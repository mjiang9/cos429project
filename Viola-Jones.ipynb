{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import random\n",
    "from dask import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import integral_image\n",
    "from skimage.feature import haar_like_feature\n",
    "from skimage.feature import haar_like_feature_coord\n",
    "from skimage.feature import draw_haar_like_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logistic import logistic_fit, logistic, logistic_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111053.47970986366"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time()\n",
    "dill.load_session('notebook_env.db')\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_face_names = sorted(glob(os.path.join('data/tests', '*.jpg')))\n",
    "n_test = len(test_face_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_inds = []\n",
    "w_inds = []\n",
    "for i in range(len(test_face_names)):\n",
    "    if int(test_face_names[i].split('_')[2]) is 0: # race is white\n",
    "        w_inds.append(i)\n",
    "    else:\n",
    "        b_inds.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nonface_names = sorted(glob(os.path.join('data/testing_nonfaces', '*.jpg')))\n",
    "n_nonfaces_test = len(test_nonface_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_t = []\n",
    "for i in range(n_test):\n",
    "    faces_t.append(cv2.imread(test_face_names[i], cv2.IMREAD_GRAYSCALE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonfaces_t = []\n",
    "for i in range(n_test):\n",
    "    # Read a random nonface file\n",
    "    j = random.randint(0, n_nonfaces_test - 1)\n",
    "    nonface = cv2.imread(test_nonface_names[j], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    wsize = random.randint(36, min(nonface.shape[0], nonface.shape[1]))\n",
    "    row = random.randint(0, nonface.shape[0]-wsize)\n",
    "    col = random.randint(0, nonface.shape[1]-wsize)\n",
    "    crop = nonface[row:row+wsize, col:col+wsize]\n",
    "\n",
    "    # Resize to be the right size\n",
    "    crop = cv2.resize(crop, (200, 200))\n",
    "    nonfaces_t.append(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_t = faces_t + nonfaces_t\n",
    "len(images_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4020"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_filenames0 = sorted(glob(os.path.join('data/train_0', '*.jpg')))\n",
    "num_face_filenames0 = len(face_filenames0)\n",
    "num_face_filenames0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4020"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_filenames25 = sorted(glob(os.path.join('data/train_25', '*.jpg')))\n",
    "num_face_filenames25 = len(face_filenames25)\n",
    "num_face_filenames25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4020"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_filenames50 = sorted(glob(os.path.join('data/train_50', '*.jpg')))\n",
    "num_face_filenames50 = len(face_filenames50)\n",
    "num_face_filenames50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4020"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_filenames75 = sorted(glob(os.path.join('data/train_75', '*.jpg')))\n",
    "num_face_filenames75 = len(face_filenames75)\n",
    "num_face_filenames75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4020"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_filenames100 = sorted(glob(os.path.join('data/train_100', '*.jpg')))\n",
    "num_face_filenames100 = len(face_filenames100)\n",
    "num_face_filenames100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4020"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for f in face_filenames0:\n",
    "    if int(f.split('_')[3]) is 0: # race is white\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonface_filenames = sorted(glob(os.path.join('data/training_nonfaces', '*.jpg')))\n",
    "num_nonface_filenames = len(nonface_filenames)\n",
    "num_nonface_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonfaces = []\n",
    "for i in range(n):\n",
    "    # Read a random nonface file\n",
    "    j = random.randint(0, num_nonface_filenames - 1)\n",
    "    nonface = cv2.imread(nonface_filenames[j], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    wsize = random.randint(50, min(nonface.shape[0], nonface.shape[1]))\n",
    "    row = random.randint(0, nonface.shape[0]-wsize)\n",
    "    col = random.randint(0, nonface.shape[1]-wsize)\n",
    "    crop = nonface[row:row+wsize, col:col+wsize]\n",
    "\n",
    "    # Resize to be the right size\n",
    "    crop = cv2.resize(crop, (200, 200))\n",
    "    nonfaces.append(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportion_b(facenames):\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        if int(facenames[i].split('_')[3]) == 0:\n",
    "            count += 1\n",
    "    return count / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.83\n",
      "0.5966666666666667\n",
      "0.31\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for f in [face_filenames0, face_filenames25, face_filenames50, face_filenames75, face_filenames100]:\n",
    "    print(proportion_b(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getimgs(facefiles):\n",
    "    faces = []\n",
    "    for i in range(n):\n",
    "        faces.append(cv2.imread(facefiles[i], cv2.IMREAD_GRAYSCALE))\n",
    "    return faces + nonfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces0 = []\n",
    "for i in range(n):\n",
    "    faces0.append(cv2.imread(face_filenames0[i], cv2.IMREAD_GRAYSCALE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Haar features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def extract_feature_image(img, feature_type, feature_coord=None):\n",
    "    \"\"\"Extract the haar feature for the current image\"\"\"\n",
    "    img = cv2.resize(img, (36,36))\n",
    "    ii = integral_image(img)\n",
    "    return haar_like_feature(ii, 0, 0, ii.shape[0], ii.shape[1],\n",
    "                             feature_type=feature_type,\n",
    "                             feature_coord=feature_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126.29814195632935"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = delayed(extract_feature_image(img, feature_types) for img in images[:20])\n",
    "# Compute the result\n",
    "t_start = time()\n",
    "X = np.array(X.compute(scheduler='threads'))\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 430920)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images0 = faces0 + nonfaces\n",
    "len(images0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image0 = cv2.resize(images0[0], (36,36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c2bf47990>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image0, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.41193127632141"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time()\n",
    "image0_ = draw_haar_like_feature(integral_image(image0), 0, 0,\n",
    "                                 36,36, \n",
    "                                 haar_like_feature_coord(36,36,feature_type=['type-2-x', 'type-2-y'])[0])\n",
    "time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 36, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image0_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = ['type-2-x', 'type-2-y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5408.295030117035"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a computation graph using Dask. This allows the use of multiple\n",
    "# CPU cores later during the actual computation\n",
    "X_t = delayed(extract_feature_image(img, feature_types) for img in images_t)\n",
    "# Compute the result\n",
    "t_start = time()\n",
    "X_t = np.array(X_t.compute(scheduler='threads'))\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = np.array([1] * n_test + [0] * n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6365.775489807129"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a computation graph using Dask. This allows the use of multiple\n",
    "# CPU cores later during the actual computation\n",
    "X = delayed(extract_feature_image(img, feature_types) for img in images0)\n",
    "# Compute the result\n",
    "t_start = time()\n",
    "X = np.array(X.compute(scheduler='threads'))\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getx(facefiles):\n",
    "    ims = getimgs(facefiles)\n",
    "    X = delayed(extract_feature_image(img, feature_types) for img in ims)\n",
    "    return np.array(X.compute(scheduler='threads'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8617.74287700653"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time()\n",
    "X25 = getx(face_filenames25)\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9534.854122877121"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time()\n",
    "X50 = getx(face_filenames50)\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7341.787719964981"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time()\n",
    "X75 = getx(face_filenames75)\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8270.294086933136"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time()\n",
    "X100 = getx(face_filenames100)\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([1] * n + [0] * n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.200968980789185"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a random forest classifier and assess its performance\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=None,\n",
    "                             n_jobs=-1, random_state=0)\n",
    "t_start = time()\n",
    "clf.fit(X, y)\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = [1]*len(faces_t) + [0]*len(nonfaces_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9416666666666667\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_t,y_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.04568600654602"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a random forest classifier and assess its performance\n",
    "rf0 = RandomForestClassifier(n_estimators=1000, max_depth=None,\n",
    "                             n_jobs=-1, random_state=0)\n",
    "t_start = time()\n",
    "rf0.fit(X0, y)\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n"
     ]
    }
   ],
   "source": [
    "print(rf0.score(X_t,y_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.97716307640076"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a random forest classifier and assess its performance\n",
    "rf25 = RandomForestClassifier(n_estimators=1000, max_depth=None,\n",
    "                             n_jobs=-1, random_state=0)\n",
    "t_start = time()\n",
    "rf25.fit(X25, y)\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n"
     ]
    }
   ],
   "source": [
    "print(rf25.score(X_t,y_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.857863903045654"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a random forest classifier and assess its performance\n",
    "rf50 = RandomForestClassifier(n_estimators=1000, max_depth=None,\n",
    "                             n_jobs=-1, random_state=0)\n",
    "t_start = time()\n",
    "rf50.fit(X50, y)\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9516666666666667\n"
     ]
    }
   ],
   "source": [
    "print(rf50.score(X_t,y_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.63540506362915"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a random forest classifier and assess its performance\n",
    "rf75 = RandomForestClassifier(n_estimators=1000, max_depth=None,\n",
    "                             n_jobs=-1, random_state=0)\n",
    "t_start = time()\n",
    "rf75.fit(X75, y)\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965\n"
     ]
    }
   ],
   "source": [
    "print(rf75.score(X_t,y_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.28110694885254"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a random forest classifier and assess its performance\n",
    "rf100 = RandomForestClassifier(n_estimators=1000, max_depth=None,\n",
    "                             n_jobs=-1, random_state=0)\n",
    "t_start = time()\n",
    "rf100.fit(X100, y)\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9683333333333334\n"
     ]
    }
   ],
   "source": [
    "print(rf100.score(X_t,y_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores, separated by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 430920), (150,), (150, 430920), (150,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use b_inds and w_inds to select rows of X_t and y_t\n",
    "Xb_t = X_t[b_inds]\n",
    "yb_t = y_t[b_inds]\n",
    "Xw_t = X_t[w_inds]\n",
    "yw_t = y_t[w_inds]\n",
    "Xb_t.shape, yb_t.shape, Xw_t.shape, yw_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "black: 0.8066666666666666\n",
      "white: 0.9733333333333334\n",
      "25\n",
      "black: 0.8333333333333334\n",
      "white: 0.9466666666666667\n",
      "50\n",
      "black: 0.86\n",
      "white: 0.9666666666666667\n",
      "75\n",
      "black: 0.9066666666666666\n",
      "white: 0.9866666666666667\n",
      "100\n",
      "black: 0.92\n",
      "white: 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "rfs = [rf0, rf25, rf50, rf75, rf100]\n",
    "for i in range(len(rfs)):\n",
    "    print(i*25)\n",
    "    print(\"black:\", rfs[i].score(Xb_t, yb_t))\n",
    "    print(\"white:\", rfs[i].score(Xw_t, yw_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/cos429/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "lr0 = LogisticRegression().fit(X0, y)\n",
    "time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time()\n",
    "score0 = lr0.score(X_t, y_t)\n",
    "time() - t_start\n",
    "score0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "# Extract all possible features\n",
    "feature_coord, feature_type = \\\n",
    "    haar_like_feature_coord(width=images.shape[2], height=images.shape[1],\n",
    "                            feature_type=feature_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_full_features = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Sort features in order of importance and plot the six most significant\n",
    "idx_sorted = np.argsort(clf.feature_importances_)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2)\n",
    "for idx, ax in enumerate(axes.ravel()):\n",
    "    image = images[0]\n",
    "    image = draw_haar_like_feature(image, 0, 0,\n",
    "                                   images.shape[2],\n",
    "                                   images.shape[1],\n",
    "                                   [feature_coord[idx_sorted[idx]]])\n",
    "    ax.imshow(image)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig.suptitle('The most important features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cos429] *",
   "language": "python",
   "name": "conda-env-cos429-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
